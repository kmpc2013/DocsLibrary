{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\udcda Bem-vindo \u00e0 Biblioteca de Documenta\u00e7\u00f5es","text":"<p>Ol\u00e1 e bem-vindo \u00e0 minha biblioteca de documenta\u00e7\u00f5es! \ud83c\udf89 Aqui voc\u00ea encontrar\u00e1 diversas informa\u00e7\u00f5es de projetos e experi\u00eancias que tive durante minha carreira. Navegue atrav\u00e9s das guias, tutoriais e refer\u00eancias para tirar o m\u00e1ximo proveito.</p>"},{"location":"#primeiros-passos","title":"\ud83d\ude80 Primeiros Passos","text":"<p>Se voc\u00ea est\u00e1 come\u00e7ando, recomendamos dar uma olhada nos seguintes documentos para se familiarizar:</p> <ul> <li>Sobre mim: Saiba mais sobre quem eu sou.</li> <li>ZmapL: Mapeando eventos de um mesmo host no Zabbix para abrir ticket com diferentes caracteristicas.</li> <li>VMware Cloud Director: Deploy de um ambiente de nuvem com VMware Cloud Director.</li> </ul>"},{"location":"#links-uteis","title":"\ud83d\udd17 Links \u00dateis","text":"<p>Aqui est\u00e3o alguns links r\u00e1pidos para minhas outras redes:</p> <ul> <li>Portif\u00f3lio</li> <li>LinkedIn</li> </ul>"},{"location":"#contatos","title":"\ud83d\udcac Contatos","text":"<p>Tem alguma d\u00favida ou precisa de ajuda? Me envie um e-mail!</p> <ul> <li>\u2709\ufe0f luis.vidio9@gmail.com.</li> <li>\ud83d\udcde (47) 98837-3112.</li> </ul> <p>Estou muito feliz por ter voc\u00ea aqui! Se precisar de algo, n\u00e3o hesite em me contactar. \ud83c\udf1f</p>"},{"location":"dicas/","title":"\ud83d\udca1 Dicas","text":"<p>Bem-vindo \u00e0 se\u00e7\u00e3o de Dicas! Aqui, voc\u00ea encontrar\u00e1 uma variedade de sugest\u00f5es valiosas para explorar novos conhecimentos.</p>","tags":["Introdu\u00e7\u00e3o"]},{"location":"dicas/kubernetes-basics/","title":"Kubernetes - Conceitos B\u00e1sicos","text":"<p>Tamb\u00e9m chamado de K8s \u00e9 um orquestrador de containers, ou seja, um sistema que visa a automa\u00e7\u00e3o do ciclo de vida dos containers, focando em implanta\u00e7\u00e3o, provisionamento, network, dimensionamento e disponibilidade.</p>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#fundamentos","title":"Fundamentos","text":"<p>Assim como o Kubernetes, tem outros orquestradores de containers no mercado, como o Docker Swarm, Red Hat OpenShift e Apache Mesos, entretanto, segundo o Google Trends, o Kubernetes est\u00e1 disparadamente mais popular que qualquer outro orquestrador: </p> <p></p> <p>De nenhuma forma estamos apontando uma superioridade ou inferioridade de qualquer player, apenas estamos identificando a popularidade dos principais players do mercado atualmente.</p> <p>Para entendermos melhor o Kubernetes, precisamos entender primeiramente alguns princ\u00edpios:</p>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#principios","title":"Princ\u00edpios","text":"<ul> <li>Imutabilidade: O principio da infraestrutura imut\u00e1vel indica que nunca deve-se realizar a\u00e7\u00f5es no sistema em funcionamento, mas sim, preparar um novo container e implementar, dessa forma, ganhando incremento de seguran\u00e7a contra indisponibilidade.</li> <li>Configura\u00e7\u00e3o declarativa: S\u00e3o arquivos para declarar tudo que o Kubernetes ir\u00e1 realizar, evitando comandos imperativos (comandos inseridos direto no terminal).</li> <li>Self-Healing System: O k8s tem op\u00e7\u00f5es e configura\u00e7\u00f5es para ele mesmo se autorrecuperar de determinadas falhas.</li> <li>Autoscale Up/Down: Escalabilidade autom\u00e1tica conforme demanda, isto \u00e9, elasticidade.</li> <li>DevOps Automation Tool: Automatizar recursos, evitando erros humanos.</li> <li>Fault Protection: A\u00e7\u00f5es preventivas contra a indisponibilidade.</li> </ul>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#componentes","title":"Componentes","text":"<ul> <li>Control Plane: \u00c9 a camada que gerencia os Workers Nodes. Todos os componentes do Control Plane s\u00e3o escal\u00e1veis horizontalmente, isto \u00e9, aumento de inst\u00e2ncias.</li> <li>API Server: Servidor de API que est\u00e1 dentro do Control Plane, ele \u00e9 a ponte que liga o Control Plane com os outros componentes, por exemplo os Workers Nodes.</li> <li>Cloud Controller Manager: Componente opcional, utilizado para se comunicar especificamente com Nuvens, seja ela qual for, para apresentar seu cluster Kubernetes para a Nuvem.</li> <li>Controller Manager: Executa os processos de controlador, ou seja, \u00e9 o c\u00e9rebro do K8s.</li> <li>etcd: Banco de dados do tipo chave-valor de c\u00f3digo aberto. Gerencia os dados de configura\u00e7\u00e3o, estado e metadados, funcionando como apoio para todos os dados do K8s.</li> <li>kube-proxy: Proxy de rede que roda em cada Work Node do cluster e viabiliza a comunica\u00e7\u00e3o de rede com os PODs.</li> <li>POD: Menor unidade computacional que pode gerenciar. Pods s\u00e3o usados para encapsular um ou mais cont\u00eaineres que compartilham o mesmo namespace de rede e armazenamento.</li> <li>Schedule: \u00c9 o componente que seleciona o node que ir\u00e1 executar determinado PODs, para isso utiliza v\u00e1rias m\u00e9tricas, como cargas de CPU, mem\u00f3ria, rede e outros.</li> <li>Kubelet: \u00c9 como um fiscal dos containers funcionarem corretamente. Este agente \u00e9 executado em cada Work Node que garante que os containers s\u00e3o executados dentro do POD correto e os recursos que o container solicita.</li> <li>CRI (Container Runtime Interface): O K8s n\u00e3o executa nenhum container propriamente dito, quem na verdade executa o container \u00e9 o CRI, que \u00e9 uma interface de abstra\u00e7\u00e3o que permite que o K8s possa se comunicar com o runtime de containers de baixo n\u00edvel. Com essa t\u00e9cnologia o K8s ganha compatibilidade com alguns runtimes do mercado, como o container-d, CRI-O, docker e outros. </li> </ul>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#yaml","title":"YAML","text":"<p>\u00c9 uma linguagem de serializa\u00e7\u00e3o de dados projetada para ser leg\u00edvel para humanos e simples, se tornando facil de usar quando precisamos definir configura\u00e7\u00f5es em arquivos.</p> <p>Caracter\u00edsticas</p> <ul> <li>N\u00e3o \u00e9 uma linguagem de marca\u00e7\u00e3o, como por exemplo o HTML.</li> <li>\u00c9 uma linguagem de serializa\u00e7\u00e3o de dados.</li> <li>\u00c9 case-sensitive</li> <li>Utiliza UTF-8 ou UTF-16</li> <li>Utiliza as exten\u00e7\u00f5es yml ou yaml</li> </ul> <p></p>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#recursos","title":"Recursos","text":"<p>Nessa etapa estaremos identificando diversos recursos do K8s e fornecendo comandos e par\u00e2metros de uso. Os comandos ser\u00e3o apresentados com o nome do recurso, cabe na hora que for utiliza-los, identificar o que precisa ser alterado no comando para corresponder ao seu ambiente.</p>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#pods","title":"Pods","text":"<p>\u00c9 a menor unidade implant\u00e1vel e gerenci\u00e1vel. Ele \u00e9 um grupo de um ou mais cont\u00eaineres (como os containers Docker), que s\u00e3o executados em um \u00fanico n\u00f3. Esses cont\u00eaineres dentro de um pod compartilham os mesmos recursos, incluindo o sistema de arquivos, endere\u00e7o IP, e as portas de rede.</p> <p>Principais par\u00e2metros:</p> <ul> <li>spec.containers</li> </ul> <p>Arquivo YAML de exemplo: <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: exemplo-pod\n  labels:\n    app: exemplo\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx:latest\n      ports:\n        - containerPort: 80\n</code></pre></p> <p>Principais comandos: <pre><code>kubectl get pods\nkubectl get pods --all-namespaces\nkubectl run my-pod-apache-server --image httpd\nkubectl get pods -o wide\nkubectl delete pods my-pod-apache-server\nkubectl delete --all pods\nkubectl create -f my-pod.yaml\nkubectl delete -f my-pod.yaml\n</code></pre></p>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#replicasets","title":"ReplicaSets","text":"<p>Um ReplicaSet \u00e9 um controlador cujo principal objetivo \u00e9 garantir que um n\u00famero especificado de r\u00e9plicas de um pod esteja em execu\u00e7\u00e3o a qualquer momento. Ele assegura que um conjunto de pods id\u00eanticos esteja dispon\u00edvel e pronto para atender \u00e0s demandas de carga da aplica\u00e7\u00e3o, proporcionando alta disponibilidade e escalabilidade.</p> <p>Principais par\u00e2metros</p> <ul> <li>spec.replicas</li> <li>spec.selector</li> <li>spec.template</li> </ul> <p>Arquivo YAML de exemplo</p> <pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: my-replicaset\n  labels:\n    app: my-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-container\n        image: my-image:latest\n        ports:\n        - containerPort: 80\n</code></pre> <p>Principais comandos</p> <pre><code>kubectl get replicaset\nkubectl create -f my-replicaset.yaml\nkubectl delete pods frontend-rs-82cm5  # Como \u00e9 um replica set, o pod ser\u00e1 recriado automaticamente\nkubectl scale replicaset frontend-rs --replicas=5 &amp;&amp; watch kubectl get pods\nkubectl delete replicaset frontend-rs\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#deployments","title":"Deployments","text":"<p>Deployment \u00e9 um recurso de n\u00edvel superior que fornece uma forma declarativa de gerenciar pods e ReplicaSets. Ele permite a implanta\u00e7\u00e3o de aplica\u00e7\u00f5es, automa\u00e7\u00e3o de atualiza\u00e7\u00f5es, a revers\u00e3o em caso de falhas, o escalonamento de aplica\u00e7\u00f5es e a manuten\u00e7\u00e3o da sa\u00fade dos pods.</p> <p>Principais par\u00e2metros</p> <ul> <li>spec.replicas</li> <li>spec.selector</li> <li>spec.template</li> </ul> <p>Arquivo YAML de exemplo</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: myapp\n        tier: frontend\n    spec:\n      containers:\n      - name: frontend\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n</code></pre> <p>Principais comandos</p> <pre><code>kubectl apply -f my-deployment.yaml\nkubectl get deployments -o wide\nkubectl get all\nkubectl rollout status deployment.apps/frontend-deployment\nkubectl describe deployment.apps/frontend-deployment\nkubectl delete deployment frontend-deployment\nkubectl rollout history deployment.apps/frontend-deployment\nkubectl rollout history deployment.apps/frontend-deployment --revision=2\nkubectl rollout undo deployment.apps/frontend-deployment\nkubectl rollout undo deployment.apps/frontend-deployment --to-revisio\nkubectl rollout pause deployment.apps/frontend-deployment\nkubectl rollout resume deployment.apps/frontend-deployment\nkubectl scale deployment.apps/frontend-deployment --replicas=2\nkubectl describe deployment.apps/frontend-deployment | grep StrategyType\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#services","title":"Services","text":"<p>Os Services em Kubernetes s\u00e3o um tipo de recurso que proporciona uma forma de expor uma aplica\u00e7\u00e3o rodando em um conjunto de Pods como um servi\u00e7o de rede. Eles permitem a comunica\u00e7\u00e3o est\u00e1vel e confi\u00e1vel entre diferentes partes de uma aplica\u00e7\u00e3o e entre aplica\u00e7\u00f5es, abstraindo a volatilidade dos Pods que podem ser criados e destru\u00eddos dinamicamente. Tendo como tipos:</p> <ul> <li>ClusterIP (Padr\u00e3o)</li> <li>NodePort</li> <li>LoadBalancer</li> <li>ExternalName</li> </ul> <p>Principais par\u00e2metros</p> <ul> <li>spec.selector</li> <li>spec.ports</li> <li>spec.type</li> </ul> <p>Arquivo YAML de exemplo <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\n  namespace: default\n  labels:\n    app: my-app\nspec:\n  selector:\n    app: my-app\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 8080\n  type: ClusterIP\n</code></pre></p> <p>Principais comandos</p> <pre><code>kubectl create -f service.yaml\nkubectl get services\nkubectl get svc --all-namespaces -o wide\nkubectl describe service my-service\nkubectl delete service my-service\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#liveness-probes","title":"Liveness Probes","text":"<p>Liveness Probes s\u00e3o verifica\u00e7\u00f5es de sa\u00fade usadas para determinar se um cont\u00eainer em um pod est\u00e1 funcionando corretamente. Se a verifica\u00e7\u00e3o de liveness falhar, o cont\u00eainer \u00e9 considerado inativo ou com problema, e o Kubernetes ir\u00e1 reinici\u00e1-lo automaticamente para tentar recuperar a aplica\u00e7\u00e3o. Tendo como tipos:</p> <ul> <li>HTTP Probe</li> <li>TCP Probe</li> <li>Exec Probe</li> </ul> <p>Principais par\u00e2metros</p> <ul> <li>spec.containers.livenessProbe.httpGet</li> <li>spec.containers.livenessProbe.initialDelaySeconds</li> <li>spec.containers.livenessProbe.periodSeconds</li> <li>spec.containers.livenessProbe.timeoutSeconds</li> <li>spec.containers.livenessProbe.failureThreshold</li> </ul> <p>Arquivo YAML de exemplo <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  containers:\n    - name: my-container\n      image: my-image:latest\n      livenessProbe:\n        httpGet:\n          path: /healthz\n          port: 8080\n        initialDelaySeconds: 30\n        periodSeconds: 10\n        timeoutSeconds: 5\n        failureThreshold: 3\n</code></pre> Principais comandos</p> <pre><code>kubectl apply -f pod.yaml\nkubectl describe pod my-pod\nkubectl logs my-pod --previous\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#volumes","title":"Volumes","text":"<p>Volumes em Kubernetes s\u00e3o recursos de armazenamento utilizados pelos pods para persistir dados al\u00e9m do ciclo de vida dos cont\u00eaineres. A abordagem de volumes em Kubernetes resolve a limita\u00e7\u00e3o dos cont\u00eaineres Docker, que perdem seus dados ao serem reiniciados. Em Kubernetes, um volume \u00e9 um diret\u00f3rio acess\u00edvel para um ou mais cont\u00eaineres em um pod, que pode armazenar dados de forma persistente. Volumes podem ter diferentes backends de armazenamento, como sistemas de arquivos locais, NFS, armazenamento em nuvem, etc.</p> <p>Tipos:</p> <ul> <li>emptyDir</li> <li>hostPath</li> <li>nfs</li> <li>persistentVolumeClain (PVC)</li> <li>configMap e secret</li> <li>Storage Classes</li> <li>volumeMounts</li> </ul> <p>Principais par\u00e2metros</p> <ul> <li>spec.containers.volumeMounts</li> <li>spec.volumes</li> </ul> <p>Arquivo YAML de exemplo <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  containers:\n    - name: my-container\n      image: my-image:latest\n      volumeMounts:\n        - name: my-emptydir\n          mountPath: /mnt/emptydir\n        - name: my-hostpath\n          mountPath: /mnt/hostpath\n        - name: my-configmap\n          mountPath: /mnt/configmap\n          readOnly: true\n        - name: my-secret\n          mountPath: /mnt/secret\n          readOnly: true\n  volumes:\n    - name: my-emptydir\n      emptyDir: {}\n    - name: my-hostpath\n      hostPath:\n        path: /data/hostpath\n        type: Directory\n    - name: my-configmap\n      configMap:\n        name: my-configmap\n    - name: my-secret\n      secret:\n        secretName: my-secret\n</code></pre> Principais comandos</p> <pre><code>kubectl apply -f pod.yaml\nwatch kubectl get pods\nkubectl get pv  # Para PersistentVolumes\nkubectl get pvc # Para PersistentVolumeClaims\nkubectl describe pod &lt;nome-do-pod&gt;\nkubectl describe pv &lt;nome-do-pv&gt;\nkubectl get pods\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#deamonsets","title":"DeamonSets","text":"<p>DaemonSet \u00e9 um tipo de recurso que garante que uma c\u00f3pia de um pod seja executada em cada n\u00f3 do cluster. Em outras palavras, ele assegura que todos os n\u00f3s, ou um subconjunto espec\u00edfico de n\u00f3s, tenham uma inst\u00e2ncia de um determinado pod rodando.  Voc\u00ea pode usar nodeSelectors, affinity e tolerations para restringir em quais n\u00f3s o DaemonSet deve ser executado.</p> <p>Principais par\u00e2metros</p> <ul> <li>spec.selector.matchLabels.app</li> <li>spec.template.metadata</li> <li>spec.template.spec</li> </ul> <p>Arquivo YAML de exemplo <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: my-daemonset\n  namespace: default\n  labels:\n    app: my-app\nspec:\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n        - name: my-container\n          image: my-image:latest\n          ports:\n            - containerPort: 80\n</code></pre> Principais comandos</p> <pre><code>kubectl apply -f daemonset.yaml\nkubectl get daemonsets\nkubectl get ds\nkubectl describe daemonset &lt;nome-do-daemonset&gt;\nkubectl delete daemonset &lt;nome-do-daemonset&gt;\nkubectl get ds/my-daemonset -o go-template='{{.spec.updateStrategy.type}}{{\"\\n\"}}' -n default\nkubectl get ds/my-daemonset -o go-template='{{.spec.updateStrategy.rollingUpdate.maxUnavailable}}{{\"\\n\"}}' -n default\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#jobs","title":"Jobs","text":"<p>Um \"Job\" \u00e9 um tipo de recurso que gerencia a execu\u00e7\u00e3o de tarefas ou trabalhos que precisam ser completados uma ou mais vezes. \u00c9 particularmente \u00fatil para tarefas que n\u00e3o precisam rodar continuamente, mas sim at\u00e9 que sejam conclu\u00eddas com sucesso.</p> <ul> <li>Objetivo: O objetivo principal de um Job \u00e9 garantir que uma ou mais tarefas sejam conclu\u00eddas. Isso \u00e9 diferente de um \"Pod\", que pode ser usado para processos cont\u00ednuos.</li> <li>Repeti\u00e7\u00e3o: Um Job pode criar um ou mais Pods para executar uma tarefa. Ele garante que o n\u00famero especificado de Pods complete sua execu\u00e7\u00e3o com sucesso. Caso um Pod falhe, o Job pode criar novos Pods para tentar novamente at\u00e9 que a tarefa seja completada com sucesso.</li> <li>Completamento: Voc\u00ea pode configurar o Job para que ele complete quando um certo n\u00famero de Pods tiverem terminado a execu\u00e7\u00e3o com sucesso. Isso \u00e9 definido pela configura\u00e7\u00e3o de completions no Job. Por exemplo, se voc\u00ea configurar completions: 5, o Job considerar\u00e1 conclu\u00eddo quando cinco Pods tiverem sido executados com sucesso.</li> <li>Retry e Paralelismo: Jobs podem ser configurados para ter m\u00faltiplas execu\u00e7\u00f5es paralelas (parallelism) e podem tentar novamente se falharem (backoffLimit). Monitoramento: Voc\u00ea pode monitorar o progresso e o estado dos Jobs usando comandos do kubectl, como <code>kubectl get jobs</code>, <code>kubectl describe job &lt;job-name&gt;</code> e <code>kubectl describe pods &lt;job-name&gt; | grep Exit</code>.</li> </ul> <p>Container Exit Codes:</p> C\u00f3digo Mensagem Resumo 1 Applicantion error Erro gen\u00e9rico ou falha na aplica\u00e7\u00e3o. 126 Command invoke error O comando n\u00e3o pode ser invocado ou executado, muitas vezes por falta de permiss\u00f5es. 127 File or directory not found O comando n\u00e3o foi encontrado. Pode indicar que o arquivo ou diret\u00f3rio n\u00e3o existe. 134 Abnormal termination O processo terminou de forma anormal, frequentemente devido a um sinal de t\u00e9rmino. 137 Immediate termination O processo foi terminado imediatamente pelo sinal SIGKILL (kill -9). 139 Segmentation fault O processo encontrou um erro de segmenta\u00e7\u00e3o, que \u00e9 um tipo de falha de acesso \u00e0 mem\u00f3ria. 255 Exit Status Out of Range O c\u00f3digo de sa\u00edda est\u00e1 fora do intervalo permitido, geralmente indicando um erro ou comportamento inesperado. 0 Purposely stopped O processo foi terminado com sucesso e sem erros. <p>Container Restart Policy:</p> <p>Define como o Kubernetes deve lidar com a reinicializa\u00e7\u00e3o dos containers quando eles falham ou s\u00e3o encerrados.</p> <ul> <li>Always \ud83e\udc2a Reinicia o container sempre, \u00fatil para servi\u00e7os cont\u00ednuos.</li> <li>OnFailure \ud83e\udc2a Reinicia o container apenas se houver falha, ideal para Jobs e tarefas.</li> <li>Never \ud83e\udc2a N\u00e3o reinicia o container, \u00fatil para containers que devem executar uma tarefa e sair.</li> </ul> <p>Principais par\u00e2metros</p> <ul> <li>spec.completions</li> <li>spec.parallelism</li> <li>spec.backoffLimit</li> <li>spec.template.spec</li> </ul> <p>Arquivo YAML de exemplo <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: my-job\n  namespace: default\nspec:\n  completions: 3\n  parallelism: 1\n  backoffLimit: 4\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n        - name: my-container\n          image: my-image:latest\n          command: [\"sh\", \"-c\", \"echo Hello, Kubernetes! &amp;&amp; sleep 30\"]\n      restartPolicy: Never\n</code></pre> Principais comandos</p> <pre><code>kubectl apply -f job.yaml\nkubectl get jobs\nkubectl get job &lt;nome-do-job&gt; --output yaml | grep type\nkubectl get job &lt;nome-do-job&gt; --output yaml | grep reason\nkubectl describe job &lt;nome-do-job&gt;\nkubectl describe pods &lt;nome-do-job&gt; | grep Status:\nkubectl describe pods &lt;nome-do-job&gt; | grep Exit\nkubectl logs &lt;nome-do-pod&gt;\nkubectl delete job &lt;nome-do-job&gt;\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#cronjobs","title":"CronJobs","text":"<p>\u00c9 um recurso que permite agendar a execu\u00e7\u00e3o de Jobs em hor\u00e1rios espec\u00edficos, semelhante ao cron no Linux. \u00c9 uma maneira poderosa de automatizar tarefas que precisam ser realizadas periodicamente.</p> <p></p> <p>CronJob Special Strings:</p> Entry Equivalence @yearly, @annually 0 0 1 1 * @monthly 0 0 1 * * @weekly 0 0 * * 0 @daily, @midnight 0 0 * * * @hourly 0 * * * * <p>Links de aux\u00edlio:</p> <ul> <li>Cronjob Schedule Editor Online.</li> </ul> <p>Principais par\u00e2metros</p> <ul> <li>spec.jobTemplate</li> <li>spec.successfulJobsHistoryLimit</li> <li>spec.failedJobsHistoryLimit</li> <li>spec.startingDeadlineSeconds</li> <li>spec.concurrencyPolicy</li> </ul> <p>Arquivo YAML de exemplo <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: my-cronjob\n  namespace: default\n  labels:\n    app: my-app\nspec:\n  schedule: \"0 2 * * *\"  # Executa todos os dias \u00e0s 2 da manh\u00e3\n  jobTemplate:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      template:\n        metadata:\n          labels:\n            app: my-app\n        spec:\n          containers:\n            - name: my-container\n              image: my-image:latest\n              command: [\"sh\", \"-c\", \"echo 'Hello, Kubernetes!'\"]\n          restartPolicy: OnFailure\n  successfulJobsHistoryLimit: 3\n  failedJobsHistoryLimit: 1\n  startingDeadlineSeconds: 600\n  concurrencyPolicy: Forbid\n</code></pre> Principais comandos</p> <pre><code>kubectl apply -f cronjob.yaml\nkubectl get cronjobs\nkubectl describe cronjob &lt;nome-do-cronjob&gt;\nkubectl patch cj my-cj -p '{\"spec\" : {\"suspend\":true}}'\nkubectl get jobs --selector=job-name=&lt;nome-do-cronjob&gt;\nkubectl delete cronjob &lt;nome-do-cronjob&gt;\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#configmaps","title":"ConfigMaps","text":"<p>Um ConfigMap \u00e9 um recurso usado para armazenar dados de configura\u00e7\u00e3o em formato chave-valor. Esses dados podem ser utilizados para configurar aplica\u00e7\u00f5es que est\u00e3o sendo executadas em um cluster Kubernetes. Podemos inserir essas configura\u00e7\u00f5es de duas forma:</p> <ul> <li>Injetado: Utilizado somente o par\u00e2metro envFrom fazendo assim que as configura\u00e7\u00f5es sejam importadas como vari\u00e1veis de ambiente dentro do Pod. Para alter\u00e1-las \u00e9 preciso redeployar o Pod, ou seja, excluir e criar novamente. Vide par\u00e2metro envFrom abaixo:</li> </ul> Exemplo - ConfigMaps Injetado <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n    name: my-cm\nnamespace: default\ndata:\n    database: mysql\n    database_uri: mysql://localhost:3306\n---\nkind: Pod\napiVersion: v1\nmetadata:\n    name: pod-cm-env\nspec:\n    containers:\n    - name: my-container\n      image: nginx\n      envFrom:\n        - configMapRef: \n          name: my-cm\n</code></pre> <ul> <li>Montado: Dessa forma \u00e9 utilizado de volumes para montar cada entrada de chave-valor do ConfigMap para ser um arquivo dentro do Pod. Dessa forma, quando alteramos o ConfigMap o arquivo \u00e9 atualizado automaticamente (Pode levar 2 minutos). Todavia, caso juntamente esteja injetando nas vari\u00e1veis de ambiente, o arquivo montado estar\u00e1 atualizado mas as vari\u00e1veis de ambiente necessitam que o Pod seja reiniciado para reler os arquivos e atualizar as vari\u00e1veis. Vide par\u00e2metro volumeMounts e volumes abaixo:</li> </ul> Exemplo - ConfigMaps Montado <pre><code>kind: ConfigMap\napiVersion: v1\nmetadata:\n  name: my-cm\n  namespace: default\ndata:\n  database: mariadb\n  database_uri: mariadb://localhost:3306\n--- \nkind: Pod\napiVersion: v1\nmetadata:\n    name: pod-cm-vol\nspec:\n    containers:\n    - name: my-container\n      image: nginx\n      volumeMounts:\n        - name: my-vol\n          mountPath: \"/etc/my-vol\"\n          readOnly: true\n\nvolumes:\n    - name: my-vol\n      configMap:\n        name: my-cm\n</code></pre> <p>\u00c9 poss\u00edvel utilizar os dois tipos de inser\u00e7\u00e3o de configura\u00e7\u00f5es simultaneamente. Vide par\u00e2metro \u201cenvFrom\u201d, \u201cvolumeMounts\u201d e \u201cvolumes\u201d:</p> Exemplo - ConfigMaps Injetado e Montado <pre><code>spec:\n    containers:\n    - name: my-container\n        image: nginx\n        envFrom:\n          - configMapRef: \n            name: my-cm\n        volumeMounts:\n          - name: my-vol\n            mountPath: \"/etc/my-vol\"\n            readOnly: true\n\nvolumes:\n- name: my-vol\n  configMap:\n    name: my-cm\n</code></pre> <p>Podemos tamb\u00e9m inserir v\u00e1rios par\u00e2metros em um arquivo apenas no container, para isso, no ConfigMap precisa ser definido como abaixo. Dessa forma, ser\u00e1 mapeado apenas um arquivo chamado my.config.db no Pod:</p> Exemplo - V\u00e1rios par\u00e2metros <pre><code>data:\n#Connection database-config\nmy.config.db: |\n    database: mariadb\n    database_uri: mariadb://localhost:3306\n</code></pre> <p>Principais par\u00e2metros</p> <ul> <li>spec.containers.volumeMounts</li> <li>volumes.configMap</li> <li>data</li> <li>binaryData</li> </ul> <p>Arquivo YAML de exemplo <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: example-configmap\n  namespace: default  # Se n\u00e3o especificado, assume o namespace padr\u00e3o\ndata:\n  # Armazenamento de dados de configura\u00e7\u00e3o como pares chave-valor\n  key1: \"value1\"\n  key2: \"value2\"\n  # Armazenamento de dados de configura\u00e7\u00e3o em m\u00faltiplas linhas\n  multiline-key: |\n    Linha 1\n    Linha 2\n    Linha 3\nbinaryData:\n  # Armazenamento de dados bin\u00e1rios codificados em base64\n  binary-key: \"dGVzdGJpbmFyeWRhdGE=\"  # \"testbinarydata\" codificado em base64\n</code></pre> Principais comandos</p> <pre><code>kubectl create configmap &lt;nome-do-configmap&gt; --from-file=&lt;caminho-do-arquivo&gt;\nkubectl create configmap &lt;nome-do-configmap&gt; --from-literal=&lt;chave&gt;=&lt;valor&gt;\nkubectl get configmaps\nkubectl describe configmap &lt;nome-do-configmap&gt;\nkubectl describe pod &lt;nome-do-pod&gt; | grep Warning\nkubectl get events | grep Warning\nkubectl apply -f &lt;caminho-do-arquivo-yaml&gt;\nkubectl delete configmap &lt;nome-do-configmap&gt;\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#secrets","title":"Secrets","text":"<p>\"Secret\" \u00e9 um recurso usado para armazenar dados sens\u00edveis, como senhas, chaves SSH, tokens de API, e certificados. A ideia \u00e9 que voc\u00ea possa gerenciar essas informa\u00e7\u00f5es de forma segura e acess\u00edvel para suas aplica\u00e7\u00f5es em execu\u00e7\u00e3o.</p> <p>Armazenamento Seguro</p> <p>Os Secrets s\u00e3o armazenados em base64 no etcd, o banco de dados do Kubernetes. Isso n\u00e3o \u00e9 criptografia, mas um m\u00e9todo simples de codifica\u00e7\u00e3o que evita a exposi\u00e7\u00e3o de dados sens\u00edveis em texto claro.  Em clusters Kubernetes configurados adequadamente, os dados dos Secrets s\u00e3o criptografados no etcd, o que adiciona uma camada extra de seguran\u00e7a.</p> <p>Cria\u00e7\u00e3o e gest\u00e3o</p> <p>Pode criar um Scret usando arquivos YAML ou JSON, ou diretamente via kubectl. Um Secret pode ter diferentes tipos, como <code>Opaque</code> (O tipo mais gen\u00e9rico), <code>docker-registry</code> (para credenciais de registro Docker) ou <code>basic-auth</code> (para autentica\u00e7\u00e3o b\u00e1sica HTTP). \u00c9 importante que os Secrets sejam manipulados com cuidado. Evite coloc\u00e1-los diretamente em arquivos de configura\u00e7\u00e3o que possam ser versionados no controle de vers\u00e3o ou expostos inadvertidamente.</p> <p>Uso em pods</p> <p>Pode montar um Secret como um volume em um pod. Isso \u00e9 \u00fatil quando voc\u00ea precisa que as aplica\u00e7\u00f5es leiam arquivos de configura\u00e7\u00e3o sens\u00edveis.</p> Exemplo <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n    name: my-pod\nspec:\n    containers:\n    - name: my-container\n    image: my-image\n    volumeMounts:\n    - name: secret-volume\n        mountPath: /etc/secret\n    volumes:\n    - name: secret-volume\n    secret:\n        secretName: my-secret\n</code></pre> <p>Voc\u00ea tamb\u00e9m pode expor Secrets como vari\u00e1veis de ambiente no container, o que \u00e9 \u00fatil para configura\u00e7\u00e3o de aplica\u00e7\u00f5es.</p> Exemplo <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  containers:\n  - name: my-container\n    image: my-image\n    env:\n    - name: DB_USERNAME\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: username\n    - name: DB_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: password\n</code></pre> <p>Boas Pr\u00e1ticas</p> <p>Restrinja o acesso aos Secrets usando RBAC (Controle de Acesso Baseado em Fun\u00e7\u00e3o). Somente os servi\u00e7os e pods que realmente precisam desses Secrets devem ter acesso. Para maior seguran\u00e7a, considere usar solu\u00e7\u00f5es externas de gerenciamento de segredos, como <code>HashiCorp Vault</code> ou <code>AWS Secrets Manager</code>, especialmente em ambientes de produ\u00e7\u00e3o.</p> <p>Built-In Type</p> <p>O termo \"bultin type\" se refere a tipos de dados integrados e pr\u00e9-definidos que voc\u00ea pode usar para criar e gerenciar Secrets.</p> <ul> <li>Opaque \ud83e\udc2a Tipo padr\u00e3o. Permite armazenar dados arbitr\u00e1rios de chave-valor. type: Opaque</li> <li>docker-registry \ud83e\udc2a Armazenar credenciais para acesso ao registries privados do Docker. type: kubernetes.io/dockerconfigjson</li> <li>basic-auth \ud83e\udc2a Armazenar credenciais de autentica\u00e7\u00e3o b\u00e1sica sendo o segredo codificado em base64. type: kubernetes.io/basic-auth</li> <li>ssh-auth \ud83e\udc2a Armazenar chaves ssh. type: kubernetes.io/ssh-auth</li> <li>TLS \ud83e\udc2a Armazenar certificados e chaves type: kubernetes.io/tls</li> <li>service-account-token \ud83e\udc2a Usado internamente pelo kubernetes para gerenciar tokens de servi\u00e7o.</li> </ul> <p>data e stringData</p> <p>S\u00e3o campos usados para armazenar os dados de um Secret, mas eles t\u00eam diferen\u00e7as importantes em como voc\u00ea deve us\u00e1-los e como os dados s\u00e3o manipulados. O campo data \u00e9 usado para armazenar dados bin\u00e1rios codificados em Base64. Isso significa que voc\u00ea precisa codificar manualmente os valores dos campos em Base64 antes de inseri-los no YAML do Secret.</p> Exemplo <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: basic-auth-secret\ntype: kubernetes.io/basic-auth\ndata:\n  username: dXNlcg==       # \"user\" em Base64\n  password: cGFzc3dvcmQ=   # \"password\" em Base64\n</code></pre> <p>O campo stringData \u00e9 usado para fornecer dados em formato de string simples, sem a necessidade de codifica\u00e7\u00e3o Base64. O Kubernetes ir\u00e1 automaticamente codificar os dados em Base64 quando o Secret for criado ou atualizado.</p> Exemplo <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: basic-auth-secret\ntype: kubernetes.io/basic-auth\nstringData:\n  username: user       # \"user\", n\u00e3o codificado\n  password: password   # \"password\", n\u00e3o codificado\n</code></pre> <p>Principais par\u00e2metros</p> <ul> <li>data.username</li> <li>data.password</li> <li>stringData.api-key</li> </ul> <p>Arquivo YAML de exemplo <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: example-secret\n  namespace: default  # Se n\u00e3o especificado, assume o namespace padr\u00e3o\ntype: Opaque\ndata:\n  username: dXNlcg==  # \"user\" codificado em base64\n  password: cGFzc3dvcmQ=  # \"password\" codificado em base64\nstringData:\n  api-key: my-secret-api-key  # \"my-secret-api-key\" ser\u00e1 convertido para base64 automaticamente\n</code></pre> Principais comandos</p> <pre><code>echo -n 'valor' | base64  # Codificar um valor em base64\nkubectl create secret generic &lt;nome-do-secret&gt; --from-file=&lt;caminho-do-arquivo&gt;\nkubectl create secret generic &lt;nome-do-secret&gt; --from-literal=&lt;chave&gt;=&lt;valor&gt;\nkubectl create secret generic &lt;nome-do-secret&gt; --from-file=&lt;caminho-do-diretorio&gt;\nkubectl get secrets\nkubectl describe secret &lt;nome-do-secret&gt;\nkubectl apply -f &lt;caminho-do-arquivo-yaml&gt;\nkubectl delete secret &lt;nome-do-secret&gt;\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#statefulsets","title":"StatefulSets","text":"<p>\u00c9 um recurso do Kubernetes projetado para gerenciar aplica\u00e7\u00f5es com estado, que exigem persist\u00eancia e identifica\u00e7\u00e3o \u00fanica para cada inst\u00e2ncia de Pod. Ele \u00e9 ideal para casos onde voc\u00ea precisa garantir que cada Pod tenha um identificador est\u00e1vel e armazenamento persistente, como em bancos de dados e outras aplica\u00e7\u00f5es que precisam de gerenciamento de estado.</p> <p>Caracter\u00edsticas Principais do StatefulSet</p> <ol> <li>Identidade Est\u00e1vel \ud83e\udc2a Cada Pod em um StatefulSet recebe um nome \u00fanico e previs\u00edvel que n\u00e3o muda durante a vida \u00fatil do Pod. Esse nome \u00e9 composto pelo nome do StatefulSet e um \u00edndice ordinal (por exemplo, myapp-0, myapp-1, etc.). Isso garante que cada Pod possa ser referenciado de forma consistente.</li> <li>Armazenamento Persistente \ud83e\udc2a  O StatefulSet pode ser configurado para usar Volumes Persistentes (Persistent Volumes - PVs) e Claims (Persistent Volume Claims - PVCs). Cada Pod recebe um Volume Persistente associado a ele que persiste mesmo se o Pod for recriado ou movido para outro n\u00f3. Isso \u00e9 essencial para aplica\u00e7\u00f5es que armazenam dados locais que precisam ser preservados.</li> <li>Orquestra\u00e7\u00e3o e Escalonamento \ud83e\udc2a O StatefulSet garante uma ordem espec\u00edfica de cria\u00e7\u00e3o e exclus\u00e3o de Pods. Os Pods s\u00e3o criados e exclu\u00eddos de forma sequencial, o que \u00e9 importante para garantir a ordem e a estabilidade durante o escalonamento e atualiza\u00e7\u00f5es.</li> <li>Acesso a Dados e Configura\u00e7\u00e3o \ud83e\udc2a Os Pods em um StatefulSet podem usar ConfigMaps e Secrets para configurar dados espec\u00edficos de cada inst\u00e2ncia. A identidade est\u00e1vel e o armazenamento persistente ajudam a garantir que cada Pod mantenha seu estado e configura\u00e7\u00e3o individual.</li> </ol> <p>Componentes do StatefulSet</p> <ul> <li>serviceName</li> <li>replicas</li> <li>selector</li> <li>template</li> <li>volumeClaimTemplates</li> </ul> <p>Casos de Uso Comuns</p> <ul> <li>Banco de dados</li> <li>Caches distribu\u00eddos</li> <li>Aplica\u00e7\u00f5es que Requerem Identidade Est\u00e1vel</li> </ul> <p>Principais par\u00e2metros</p> <ul> <li>spec.serviceName</li> <li>spec.replicas</li> <li>spec.selector</li> <li>spec.template</li> <li>spec.volumeClaimTemplates</li> </ul> <p>Arquivo YAML de exemplo <pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: example-statefulset\n  namespace: default  # Se n\u00e3o especificado, assume o namespace padr\u00e3o\nspec:\n  serviceName: \"example-service\"  # Nome do servi\u00e7o associado ao StatefulSet\n  replicas: 3  # N\u00famero de r\u00e9plicas desejado\n  selector:\n    matchLabels:\n      app: example\n  template:\n    metadata:\n      labels:\n        app: example\n    spec:\n      containers:\n      - name: example-container\n        image: nginx:latest\n        ports:\n        - containerPort: 80\n          name: http\n        volumeMounts:\n        - name: example-storage\n          mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n  - metadata:\n      name: example-storage\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      resources:\n        requests:\n          storage: 1Gi\n</code></pre> Principais comandos</p> <pre><code>kubectl apply -f &lt;caminho-do-arquivo-yaml&gt;\nkubectl get statefulsets\nkubectl describe statefulset &lt;nome-do-statefulset&gt;\nkubectl scale statefulset &lt;nome-do-statefulset&gt; --replicas=&lt;n\u00famero-de-r\u00e9plicas&gt;\nkubectl get persistentvolumeclaim\nkubectl patch pv &lt;nome-do-pvc&gt; -p '{\"spec\": {\"persistentVolumeReclaimPolicy\":\"Retain\"}}'\nsudo updatedb &amp;&amp; sudo locate &lt;nome-do-pvc&gt;\nkubectl delete statefulset &lt;nome-do-statefulset&gt;\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#endpoints","title":"Endpoints","text":"<p>Um endpoint \u00e9 uma lista de IPs e portas que s\u00e3o associados a um servi\u00e7o. O Kubernetes usa endpoints para descobrir e se conectar aos pods que pertencem a um servi\u00e7o. Quando voc\u00ea cria um servi\u00e7o, o Kubernetes automaticamente cria um objeto Endpoints que inclui as informa\u00e7\u00f5es sobre os pods que correspondem ao servi\u00e7o.</p> <p>Nota</p> <p>O Endpoint e o Service devem ter o mesmo nome para que o Kubernetes automaticamente vincule esses dois recursos.</p> <p>Como Funciona</p> <ol> <li>Quando voc\u00ea cria um servi\u00e7o no Kubernetes, o controlador de servi\u00e7o busca todos os pods que correspondem aos seletores definidos no servi\u00e7o.</li> <li>O controlador de endpoints ent\u00e3o cria um objeto Endpoints que cont\u00e9m informa\u00e7\u00f5es sobre esses pods, incluindo seus IPs e portas.</li> <li>Esse objeto Endpoints \u00e9 atualizado dinamicamente sempre que h\u00e1 altera\u00e7\u00f5es nos pods que correspondem ao servi\u00e7o.</li> </ol> <p>Vis\u00e3o Geral</p> <ul> <li>Objetivo: O objetivo principal dos endpoints \u00e9 fornecer uma maneira para o servi\u00e7o saber quais pods est\u00e3o dispon\u00edveis e onde eles est\u00e3o.</li> <li>Atualiza\u00e7\u00f5es Din\u00e2micas: Eles s\u00e3o atualizados automaticamente pelo Kubernetes conforme os pods s\u00e3o criados ou destru\u00eddos, garantindo que o servi\u00e7o sempre tenha informa\u00e7\u00f5es precisas sobre como alcan\u00e7ar os pods correspondentes.</li> </ul> <p>Principais par\u00e2metros</p> <ul> <li>subsets.addresses</li> <li>subsets.ports</li> </ul> <p>Arquivo YAML de exemplo <pre><code>apiVersion: v1\nkind: Endpoints\nmetadata:\n  name: example-endpoints\n  namespace: default  # Se n\u00e3o especificado, assume o namespace padr\u00e3o\nsubsets:\n  - addresses:\n    - ip: 10.0.0.1\n    - ip: 10.0.0.2\n    ports:\n    - name: http\n      port: 80\n      protocol: TCP\n</code></pre> Principais comandos</p> <pre><code>kubectl get endpoints\nkubectl describe endpoints &lt;nome-do-endpoints&gt;\nkubectl apply -f &lt;caminho-do-arquivo-yaml&gt;\nkubectl delete endpoints &lt;nome-do-endpoints&gt;\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#endpointslice","title":"EndpointSlice","text":"<p>Nos clusters Kubernetes grandes, onde h\u00e1 um grande n\u00famero de pods e servi\u00e7os, o recurso Endpoints pode se tornar um gargalo em termos de desempenho. O objeto Endpoints armazena todos os IPs e portas dos pods correspondentes a um servi\u00e7o em um \u00fanico recurso, o que pode levar a problemas de desempenho e escalabilidade. EndpointSlice \u00e9 uma API que foi introduzida para resolver esses problemas. Ele divide a lista de endpoints em v\u00e1rios objetos menores, chamados \"slices\", que s\u00e3o mais f\u00e1ceis de gerenciar e mais eficientes para o cluster</p> <p></p> <p>Principais par\u00e2metros</p> <p>Arquivo YAML de exemplo <pre><code>apiVersion: discovery.k8s.io/v1\nkind: EndpointSlice\nmetadata:\n  name: example-endpointslice\n  namespace: default  # Se n\u00e3o especificado, assume o namespace padr\u00e3o\n  labels:\n    kubernetes.io/service-name: example-service\naddressType: IPv4\nendpoints:\n  - addresses:\n    - 10.0.0.1\n    - 10.0.0.2\n    ports:\n    - name: http\n      port: 80\n      protocol: TCP\n  - addresses:\n    - 10.0.0.3\n    ports:\n    - name: http\n      port: 80\n      protocol: TCP\n</code></pre> Principais comandos</p> <pre><code>kubectl get endpointslices\nkubectl describe endpointslice &lt;nome-do-endpointslice&gt;\nkubectl apply -f &lt;caminho-do-arquivo-yaml&gt;\nkubectl delete endpointslice &lt;nome-do-endpointslice&gt;\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#rbac","title":"RBAC","text":"<p>RBAC (Role-Based Access Control) \u00e9 um mecanismo de controle de acesso utilizado no Kubernetes para gerenciar permiss\u00f5es e autoriza\u00e7\u00f5es dentro de um cluster. Ele permite que voc\u00ea defina e controle quais a\u00e7\u00f5es os usu\u00e1rios e aplica\u00e7\u00f5es podem realizar em recursos do Kubernetes, como pods, servi\u00e7os e namespaces.</p> <p>Conceitos B\u00e1sicos</p> <ol> <li>Roles (Pap\u00e9is):<ul> <li>Um Role define um conjunto de permiss\u00f5es dentro de um namespace espec\u00edfico. Essas permiss\u00f5es especificam quais a\u00e7\u00f5es podem ser realizadas em quais recursos. Por exemplo, um Role pode permitir listar e obter pods em um namespace espec\u00edfico.</li> <li>ClusterRole \u00e9 similar a um Role, mas suas permiss\u00f5es se aplicam a todo o cluster, n\u00e3o apenas a um namespace.</li> </ul> </li> <li>RoleBindings e ClusterRoleBindings:<ul> <li>Um RoleBinding associa um Role a um usu\u00e1rio ou grupo de usu\u00e1rios dentro de um namespace espec\u00edfico. Isso concede as permiss\u00f5es definidas pelo Role aos usu\u00e1rios ou grupos especificados.</li> <li>Um ClusterRoleBinding faz algo semelhante, mas associa um ClusterRole a um usu\u00e1rio ou grupo em todo o cluster, n\u00e3o apenas em um namespace.</li> </ul> </li> <li>Subjects:<ul> <li>Em RoleBindings e ClusterRoleBindings, os subjects podem ser usu\u00e1rios, grupos, ou contas de servi\u00e7o (Service Accounts). Eles s\u00e3o as entidades que recebem as permiss\u00f5es definidas pelos roles.</li> </ul> </li> <li>Rules (Regras):<ul> <li>Dentro de um Role ou ClusterRole, as regras definem os recursos e as a\u00e7\u00f5es permitidas. Por exemplo, uma regra pode permitir a a\u00e7\u00e3o de get, list, e watch em pods.</li> <li>get, list, watch, create, update, patch, delete, deletecollection, approve, bind</li> </ul> </li> </ol> <p>Principais par\u00e2metros</p> <ul> <li>rules</li> <li>roleRef</li> </ul> <p>Arquivo YAML de exemplo</p> <p>Exemplo de Role</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: example-role\n  namespace: default\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"pods\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> <p>Exemplo de ClusterRole</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: example-clusterrole\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"nodes\"]\n    verbs: [\"get\", \"list\"]\n  - apiGroups: [\"apps\"]\n    resources: [\"deployments\"]\n    verbs: [\"create\", \"delete\"]\n</code></pre> <p>Exemplo de RoleBinding</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: example-rolebinding\n  namespace: default\nsubjects:\n  - kind: User\n    name: john.doe\n    apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: example-role\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>Exemplo de ClusterRoleBinding</p> <p><pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: example-clusterrolebinding\nsubjects:\n  - kind: ServiceAccount\n    name: default\n    namespace: default\nroleRef:\n  kind: ClusterRole\n  name: example-clusterrole\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> Principais comandos</p> <pre><code>kubectl apply -f &lt;caminho-do-arquivo-role-yaml&gt;\nkubectl apply -f &lt;caminho-do-arquivo-clusterrole-yaml&gt;\nkubectl apply -f &lt;caminho-do-arquivo-rolebinding-yaml&gt;\nkubectl apply -f &lt;caminho-do-arquivo-clusterrolebinding-yaml&gt;\nkubectl get roles --namespace=&lt;namespace&gt;\nkubectl get clusterroles\nkubectl get rolebindings --namespace=&lt;namespace&gt;\nkubectl get clusterrolebindings\nkubectl describe role &lt;nome-do-role&gt; --namespace=&lt;namespace&gt;\nkubectl describe clusterrole &lt;nome-do-clusterrole&gt;\nkubectl describe rolebinding &lt;nome-do-rolebinding&gt; --namespace=&lt;namespace&gt;\nkubectl describe clusterrolebinding &lt;nome-do-clusterrolebinding&gt;\n</code></pre> <pre><code>mkdir certificate\ncd certificate/\nopenssl genrsa -out auditor.key 2048\nopenssl req -new -key auditor.key -out auditor.csr -subj \"/CN=auditor/O=MyCompany\"\nopenssl x509 -req -in auditor.csr -CA ~/.minikube/ca.crt -CAkey ~/.minikube/ca.key -CAcreateserial -out auditor.crt -days 365\nkubectl config set-credentials auditor --client-certificate=auditor.crt --client-key=auditor.key\nkubectl config set-context auditor-context --cluster=minikube --user=auditor\nkubectl config view\nkubectl config use-context auditor-context\nkubectl config current-context\nkubectl get pods\nkubectl auth can-i '*' '*' --all-namespaces\nkubectl auth can-i '*' '*' -n=default\nkubectl auth can-i get pods\n</code></pre>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#comandos-uteis","title":"Comandos \u00fateis","text":"<ul> <li><code>kubectl run -it &lt;pod_name&gt; --image=&lt;image_name&gt; bash</code></li> <li><code>kubectl get pods -o wide</code></li> <li><code>kubectl delete pods &lt;pod_name&gt;</code></li> <li><code>kubectl apply -f &lt;yaml_file&gt;</code></li> </ul>","tags":["Kubernetes","Linux"]},{"location":"dicas/kubernetes-basics/#boas-praticas","title":"Boas pr\u00e1ticas","text":"<ul> <li>Sempre utilizar arquivos de manifesto para aplicar as configura\u00e7\u00f5es.</li> <li>Evitar ao m\u00e1ximo configura\u00e7\u00f5es direto no terminal</li> <li>O ambiente kubernetes deve refletir exatamente o que tem nos arquivos de manifesto, armazenados no FileServer.</li> <li>Os arquivos de manifesto devem ser mantidos com versionamento, a fim de conseguirmos mapear mudan\u00e7as quando necess\u00e1rios, por exemplo, num troubleshooting.</li> </ul>","tags":["Kubernetes","Linux"]},{"location":"dicas/markdown-basics/","title":"Markdown - Comandos b\u00e1sicos","text":"<p>Markdown \u00e9 uma linguagem de marca\u00e7\u00e3o leve, amplamente utilizada para formatar texto de forma simples e leg\u00edvel, tanto em sua forma \"bruta\" quanto quando convertida para HTML ou outros formatos. Criada por John Gruber e Aaron Swartz, o objetivo principal do Markdown \u00e9 permitir que documentos de texto sejam facilmente leg\u00edveis e edit\u00e1veis, enquanto ainda podem ser convertidos para uma apresenta\u00e7\u00e3o mais rica.</p> <p></p> Titula\u00e7\u00e3o <p>A titula\u00e7\u00e3o em Markdown \u00e9 usada para definir diferentes n\u00edveis de cabe\u00e7alhos, que s\u00e3o essenciais para organizar o conte\u00fado de forma hier\u00e1rquica e facilitar a leitura. Em Markdown, os cabe\u00e7alhos s\u00e3o criados usando o s\u00edmbolo de hashtag (#). Dependendo do n\u00famero de hashtags usadas, voc\u00ea pode definir cabe\u00e7alhos de diferentes n\u00edveis. Al\u00e9m de hashtags, alguns editores de Markdown suportam a titula\u00e7\u00e3o HTML \"h1, h2, h3, ...\":</p> C\u00f3digo<pre><code># T\u00edtulo 1\n&lt;h1&gt; T\u00edtulo 1 &lt;/h1&gt;\n[...]\n###### T\u00edtulo 6\n&lt;h6&gt; T\u00edtulo 6 &lt;/h6&gt;\n</code></pre> <p>Retorno</p> <p></p> \u00canfase <p>A \u00eanfase em Markdown \u00e9 usada para aplicar formata\u00e7\u00e3o especial ao texto, como it\u00e1lico e negrito:</p> C\u00f3digo<pre><code>*texto em it\u00e1lico*\n_texto em it\u00e1lico_\n**texto em negrito**\n__texto em negrito__\n***texto em it\u00e1lico e negrito***\n___texto em it\u00e1lico e negrito___\n</code></pre> <p>Retorno</p> <p>texto em it\u00e1lico</p> <p>texto em it\u00e1lico</p> <p>texto em negrito</p> <p>texto em negrito</p> <p>texto em it\u00e1lico e negrito</p> <p>texto em it\u00e1lico e negrito</p> <p></p> Links <p>Os links em Markdown permitem que voc\u00ea crie hiperlinks de maneira simples e leg\u00edvel:</p> C\u00f3digo<pre><code>[Texto do Link](http://exemplo.com)\n[Texto do Link](http://exemplo.com \"T\u00edtulo do Link\")\n&lt;http://exemplo.com&gt;\n[![Texto Alternativo da Imagem](http://exemplo.com/imagem.png)](http://exemplo.com)\n\n[texto do link]: http://exemplo.com \"T\u00edtulo Opcional\"\nEste \u00e9 um [link de refer\u00eancia][texto do link].\n</code></pre> <p>Retorno</p> <p>Texto do Link</p> <p>Texto do Link</p> <p>http://exemplo.com</p> <p></p> <p>Este \u00e9 um link de refer\u00eancia.</p> <p></p> \u00c2ncoras <p>\u00c2ncoras em Markdown permitem criar links internos dentro de um documento, facilitando a navega\u00e7\u00e3o para diferentes se\u00e7\u00f5es. Elas s\u00e3o especialmente \u00fateis em documentos longos com v\u00e1rias se\u00e7\u00f5es, como tutoriais, manuais e guias. Para isso, caso esteja utilizando titulos com \"#\" os IDs s\u00e3o criados seguindo as seguintes m\u00e9tricas:</p> <ul> <li>Espa\u00e7os s\u00e3o substitu\u00eddos por h\u00edfens (-).</li> <li>Todos os caracteres s\u00e3o convertidos para min\u00fasculas.</li> <li>Caracteres especiais (exceto h\u00edfens) s\u00e3o removidos.</li> </ul> <p>Caso esteja utilizando \"&lt;h1&gt;\" pode utilizar a tag \"name\" para definir o ID, por exemplo <code>&lt;h1 name=\"secao-name\"&gt;TITULO&lt;/h1&gt;\"</code>:</p> C\u00f3digo<pre><code>- [Se\u00e7\u00e3o titula\u00e7\u00e3o](#secao-titulacao)\n- [Se\u00e7\u00e3o \u00eanfase](#secao-enfase)\n- [Se\u00e7\u00e3o links](#secao-links)\n</code></pre> <p>Retorno</p> <ul> <li>Se\u00e7\u00e3o titula\u00e7\u00e3o</li> <li>Se\u00e7\u00e3o \u00eanfase</li> <li>Se\u00e7\u00e3o links</li> </ul> <p></p> Listas <p>listas s\u00e3o uma maneira pr\u00e1tica de organizar informa\u00e7\u00f5es em um formato estruturado. Existem dois tipos principais de listas que voc\u00ea pode criar: listas ordenadas e listas n\u00e3o ordenadas:</p> Listas N\u00e3o Ordenadas: <p>Voc\u00ea pode criar listas n\u00e3o ordenadas usando asteriscos (*), h\u00edfens (-) ou sinais de mais (+). Todos funcionam da mesma maneira.</p> C\u00f3digo<pre><code>- Item 1\n- Item 2\n  - Subitem 1\n  - Subitem 2\n</code></pre> <p>Retorno</p> <ul> <li>Item 1</li> <li>Item 2<ul> <li>Subitem 1</li> <li>Subitem 2</li> </ul> </li> </ul> Listas Ordenadas: <p>Listas ordenadas s\u00e3o usadas quando a ordem dos itens \u00e9 importante. Elas s\u00e3o criadas usando n\u00fameros seguidos por um ponto (.). C\u00f3digo<pre><code>1. Primeiro item\n2. Segundo item\n   1. Subitem 1\n   2. Subitem 2\n3. Terceiro item\n</code></pre></p> <p>Retorno</p> <ol> <li>Primeiro item</li> <li>Segundo item<ol> <li>Subitem 1</li> <li>Subitem 2</li> </ol> </li> <li>Terceiro item</li> </ol> <p></p> Cita\u00e7\u00f5es <p>S\u00e3o usadas para destacar texto, como trechos de artigos, livros, ou qualquer outra fonte de informa\u00e7\u00e3o. Elas s\u00e3o especialmente \u00fateis para refer\u00eancias, coment\u00e1rios ou notas adicionais: C\u00f3digo<pre><code>&gt; ### Titulo de cita\u00e7\u00e3o\n&gt; Este \u00e9 um n\u00edvel de cita\u00e7\u00e3o.\n&gt;&gt; Este \u00e9 um n\u00edvel aninhado de cita\u00e7\u00e3o.\n</code></pre></p> <p>Retorno</p> <p></p> C\u00f3digo <p>Inserir c\u00f3digo em Markdown \u00e9 bastante simples e pode ser feito de duas maneiras principais: c\u00f3digo inline e blocos de c\u00f3digo: C\u00f3digo<pre><code>Para exibir `c\u00f3digo inline`, use crases simples.\n```\nPara exibir multiplas\nlinhas\nde\nc\u00f3digo\nuse tr\u00e9s crases\n```\n``` python title=\"C\u00f3digo\"\n# Pode colocar a linguaguem ao lado das crases \n# para habilitar a colora\u00e7\u00e3o e \n# a tag \"title\" para definir o titulo.\ndef funcao():\n  print(\"string\")\n```\n</code></pre></p> <p>Retorno</p> <p>Para exibir <code>c\u00f3digo inline</code>, use crases simples. <pre><code>Para exibir multiplas\nlinhas\nde\nc\u00f3digo\nuse tr\u00e9s crases\n</code></pre> C\u00f3digo<pre><code># Pode colocar a linguaguem ao lado das crases \n# para habilitar a colora\u00e7\u00e3o e \n# a tag \"title\" para definir o titulo.\ndef funcao():\n  print(\"string\")\n</code></pre></p> <p></p> Tabelas <p>s\u00e3o uma maneira eficaz de organizar e apresentar dados de forma clara e estruturada. A sintaxe \u00e9 simples e permite criar tabelas com cabe\u00e7alhos, colunas e linhas. Uma tabela em Markdown \u00e9 criada usando pipes (|) para separar colunas e hifens (-) para separar os cabe\u00e7alhos das linhas da tabela. Voc\u00ea pode controlar o alinhamento das colunas usando dois pontos (:) nos hifens: - Alinhamento \u00e0 esquerda: :--- - Alinhamento ao centro: :---: - Alinhamento \u00e0 direita: ---: As tabelas podem incluir linhas de cabe\u00e7alho, e voc\u00ea pode adicionar m\u00faltiplas linhas se necess\u00e1rio. A estrutura permanece a mesma.</p> C\u00f3digo<pre><code>| Fruta    | Cor      | Quantidade |\n|:---------|:--------:|-----------:|\n| Ma\u00e7\u00e3     | Vermelha |         10 |\n| Banana   | Amarela  |          6 |\n| Laranja  | Laranja  |          8 |\n</code></pre> <p>Retorno</p> Fruta Cor Quantidade Ma\u00e7\u00e3 Vermelha 10 Banana Amarela 6 Laranja Laranja 8 <p></p> Linhas <p>linhas s\u00e3o usadas para criar separadores ou dividir o conte\u00fado visualmente:</p> <ul> <li>Tr\u00eas ou mais asteriscos (***)</li> <li>Tr\u00eas ou mais hifens (---)</li> <li>Tr\u00eas ou mais underlines (___)</li> </ul> C\u00f3digo<pre><code>---\n___\n</code></pre> <p>Retorno</p>","tags":["HTML5","Markdown"]},{"location":"dicas/markdown-basics/#titulo-1","title":"T\u00edtulo 1 T\u00edtulo 1","text":"<p> [...]</p>","tags":["HTML5","Markdown"]},{"location":"dicas/markdown-basics/#titulo-6","title":"T\u00edtulo 6 T\u00edtulo 6","text":"","tags":["HTML5","Markdown"]},{"location":"dicas/markdown-basics/#titulo-de-citacao","title":"Titulo de cita\u00e7\u00e3o","text":"<p>Este \u00e9 um n\u00edvel de cita\u00e7\u00e3o.</p> <p>Este \u00e9 um n\u00edvel aninhado de cita\u00e7\u00e3o.</p>","tags":["HTML5","Markdown"]},{"location":"dicas/terraform-pipeline/","title":"Terraform pipeline","text":"<p>Neste documento, vamos primeiro explorar brevemente o conceito de Terraform e, em seguida, entender o que \u00e9 uma pipeline. Depois, combinaremos esses dois conceitos para criar um guia pr\u00e1tico de implementa\u00e7\u00e3o de pipelines, utilizando as ferramentas de CI do Azure e do GitLab.</p>","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"dicas/terraform-pipeline/#sumario","title":"Sum\u00e1rio","text":"<p>Antes de entrar em explica\u00e7\u00f5es detalhadas, vou apresentar um guia r\u00e1pido das etapas. Se voc\u00ea j\u00e1 est\u00e1 familiarizado com as tecnologias e apenas precisa de uma vis\u00e3o geral para relembrar os passos necess\u00e1rios, este resumo ser\u00e1 suficiente.</p> <p></p> <ul> <li>1 - Se\u00e7\u00e3o Credenciais Cloud</li> <li>2 - Acompanhar CI</li> </ul>","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"dicas/terraform-pipeline/#o-que-e-terraform","title":"O que \u00e9 Terraform?","text":"<p>\u00c9 uma ferramenta de Infraestrutura como C\u00f3digo (IaC), criada pela HashiCorp, que permite definir e provisionar infraestrutura em ambientes de nuvem (como AWS, Azure, GCP) ou em ambientes locais. Ele permite que toda a infraestrutura seja descrita como c\u00f3digo, facilitando a automa\u00e7\u00e3o, versionamento e gerenciamento de recursos.</p> <ul> <li>Infraestrutura como C\u00f3digo (IaC): A ideia de IaC \u00e9 que a infraestrutura (servidores, redes, armazenamento, etc.) seja descrita em arquivos de c\u00f3digo, e n\u00e3o configurada manualmente. Isso proporciona maior controle, automa\u00e7\u00e3o e rastreabilidade.</li> <li>HCL (HashiCorp Configuration Language): O Terraform usa essa linguagem para descrever os recursos da infraestrutura de forma declarativa. Por exemplo, voc\u00ea define o estado desejado da infraestrutura, e o Terraform ajusta os recursos para coincidir com esse estado.</li> </ul> Exemplo - Criando uma inst\u00e2ncia EC2 na AWS<pre><code>provider \"aws\" {\n  region = \"us-east-1\"\n}\n\nresource \"aws_instance\" \"example\" {\n  ami           = \"ami-123456\"\n  instance_type = \"t2.micro\"\n}\n</code></pre>","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"dicas/terraform-pipeline/#o-que-e-pipeline","title":"O que \u00e9 Pipeline?","text":"<p>Um Pipeline \u00e9 um conjunto de etapas ou processos automatizados que s\u00e3o executados em sequ\u00eancia, com o objetivo de integrar, testar e entregar software ou infraestrutura de forma eficiente e cont\u00ednua.</p> <ul> <li>Uso em CI/CD: Nos ambientes de desenvolvimento e opera\u00e7\u00f5es, pipelines s\u00e3o comumente usados em CI/CD (Integra\u00e7\u00e3o Cont\u00ednua e Entrega Cont\u00ednua). Eles automatizam o processo de compila\u00e7\u00e3o, testes, valida\u00e7\u00e3o e implanta\u00e7\u00e3o de c\u00f3digo, garantindo que o software seja entregue rapidamente e com qualidade.</li> <li>Fases t\u00edpicas: Compila\u00e7\u00e3o, testes, deploy e monitoramento.</li> <li>Ferramentas comuns: Azure Pipelines, GitLab CI, Jenkins, GitHub Actions, CircleCI, TravisCI, dentre outros.</li> </ul> Exemplo - GitLab CI - Pipeline em tr\u00eas fases: build, test e deploy<pre><code>stages:\n  - build\n  - test\n  - deploy\n\nbuild:\n  stage: build\n  script:\n    - echo \"Building project...\"\n\ntest:\n  stage: test\n  script:\n    - echo \"Running tests...\"\n\ndeploy:\n  stage: deploy\n  script:\n    - echo \"Deploying project...\"\n</code></pre>","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"dicas/terraform-pipeline/#o-que-e-terraform-pipeline","title":"O que \u00e9 Terraform Pipeline?","text":"<p>O Terraform Pipeline \u00e9 a combina\u00e7\u00e3o do Terraform com os processos de um pipeline, resultando em um fluxo automatizado para gerenciar e provisionar infraestrutura de maneira consistente e eficiente.</p> <p>Um Terraform Pipeline integra a execu\u00e7\u00e3o do c\u00f3digo Terraform dentro de um pipeline de CI/CD, automatizando as etapas necess\u00e1rias para gerenciar a infraestrutura. Ele pode incluir fases como:</p> <ul> <li>Valida\u00e7\u00e3o do c\u00f3digo Terraform (terraform validate)</li> <li>Cria\u00e7\u00e3o de um plano de execu\u00e7\u00e3o (terraform plan) para mostrar as mudan\u00e7as que ser\u00e3o aplicadas na infraestrutura</li> <li>Revis\u00e3o e aprova\u00e7\u00e3o manual (opcional), onde o plano gerado pode ser revisado por administradores ou desenvolvedores antes de aplicar as mudan\u00e7as</li> <li>Aplica\u00e7\u00e3o das mudan\u00e7as (terraform apply), onde o c\u00f3digo \u00e9 executado e os recursos s\u00e3o provisionados ou modificados</li> </ul> <p>Benef\u00edcios do Terraform Pipeline:</p> <ul> <li>Automatiza\u00e7\u00e3o completa: Reduz a necessidade de interven\u00e7\u00e3o manual e garante que a infraestrutura seja gerida de maneira automatizada e consistente.</li> <li>Colabora\u00e7\u00e3o e rastreabilidade: Como o c\u00f3digo \u00e9 versionado e executado dentro de um pipeline, todas as mudan\u00e7as ficam documentadas e revis\u00e1veis.</li> <li>Escalabilidade e consist\u00eancia: Permite que grandes equipes ou empresas gerenciem infraestruturas em v\u00e1rias nuvens e ambientes de maneira uniforme.</li> </ul> Exemplo - Pipeline Terraform com GitLab CI<pre><code>stages:\n  - init\n  - validate\n  - plan\n  - apply\n\nvariables:\n  TF_VERSION: \"1.4.6\"  # Vers\u00e3o do Terraform\n  TF_WORKSPACE: \"default\"  # Workspace que ser\u00e1 utilizado\n\n# Imagem do Docker com Terraform para executar os comandos\nimage: hashicorp/terraform:${TF_VERSION}\n\nbefore_script:\n  - terraform --version\n  - terraform workspace select ${TF_WORKSPACE} || terraform workspace new ${TF_WORKSPACE}\n\ncache:\n  paths:\n    - .terraform/\n\n# Etapa de inicializa\u00e7\u00e3o do Terraform\ninit:\n  stage: init\n  script:\n    - terraform init\n\n# Etapa de valida\u00e7\u00e3o do c\u00f3digo Terraform\nvalidate:\n  stage: validate\n  script:\n    - terraform validate\n\n# Etapa de gera\u00e7\u00e3o do plano Terraform\nplan:\n  stage: plan\n  script:\n    - terraform plan -out=tfplan\n  artifacts:\n    paths:\n      - tfplan  # Armazena o plano para ser aplicado posteriormente\n\n# Etapa de aplica\u00e7\u00e3o do plano Terraform\napply:\n  stage: apply\n  when: manual  # Define que a aplica\u00e7\u00e3o \u00e9 manual para aprova\u00e7\u00e3o humana\n  script:\n    - terraform apply -auto-approve tfplan\n</code></pre>","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"dicas/terraform-pipeline/#implementacao-de-pipelines","title":"Implementa\u00e7\u00e3o de pipelines","text":"","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"dicas/terraform-pipeline/#credenciais-cloud","title":"Credenciais Cloud","text":"<p>Antes de iniciar a cria\u00e7\u00e3o do pipeline, \u00e9 necess\u00e1rio primeiro coletar as credenciais das plataformas de nuvem que ser\u00e3o utilizadas. Neste guia, utilizaremos o Azure e a AWS como exemplos.</p>","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"dicas/terraform-pipeline/#aws-coletando-credenciais-para-o-terraform","title":"AWS - Coletando credenciais para o terraform","text":"<p>No Terraform as credencias de acesso podem ser exportadas como vari\u00e1veis de ambiente, principalmente em ambientes linux. Ent\u00e3o para criar uma paridade de nomenclatura entre o Terraform e o Portal da AWS, estaremos indicando as credenciais com o mesmo nome de quando utilizado variaveis de ambiente. Dito isto, segue abaixo:</p> <ul> <li>AWS_ACCESS_KEY_ID</li> <li>AWS_SECRET_ACCESS_KEY</li> </ul> <p>Partimos de que j\u00e1 tenha uma conta no AWS, com isso, fa\u00e7a o login com sua conta no portal do AWS.</p> <ol> <li>AWS_ACCESS_KEY_ID<ul> <li>IAM &gt; Usu\u00e1rios &gt; Adicionar usu\u00e1rios &gt; [Defina um nome] &gt; Pr\u00f3ximo &gt; Anexar pol\u00edticas diretamente &gt; AdministratorAccess &gt; Pr\u00f3ximo &gt; Criar usu\u00e1rio</li> <li>[Clique no usu\u00e1rio criado] &gt; Credenciais de seguran\u00e7a &gt; Criar chave de acesso &gt; Aplica\u00e7\u00e3o executada fora da AWS &gt; Pr\u00f3ximo &gt; Criar chave de acesso</li> <li>Copie \"Chave de acesso\"</li> </ul> </li> <li>AWS_SECRET_ACCESS_KEY<ul> <li>Copie \"Chave de acesso secreta\"</li> </ul> </li> </ol>","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"dicas/terraform-pipeline/#azure-coletando-credenciais-para-o-terraform","title":"Azure - Coletando credenciais para o terraform","text":"<p>No Terraform as credencias de acesso podem ser exportadas como vari\u00e1veis de ambiente, principalmente em ambientes linux. Ent\u00e3o para criar uma paridade de nomenclatura entre o Terraform e o Portal do Azure, estaremos indicando as credenciais com o mesmo nome de quando utilizado variaveis de ambiente. Dito isto, segue abaixo:</p> <ul> <li>ARM_CLIENT_ID</li> <li>ARM_CLIENT_SECRET</li> <li>ARM_TENANT_ID</li> <li>ARM_SUBSCRIPTION_ID</li> </ul> <p>Partimos de que j\u00e1 tenha uma conta no Azure, com isso, fa\u00e7a o login com sua conta no portal do Azure.</p> <ol> <li>ARM_CLIENT_ID<ul> <li>Portal Azure &gt; Microsoft Entra ID &gt; Registros de Aplicativo &gt; + Novo registro &gt; [Define um nome] &gt; Registrar</li> <li>Copie \"ID do aplicativo (cliente)\"</li> </ul> </li> <li>ARM_TENANT_ID<ul> <li>Entre no registro criado na etapa \"ARM_CLIENT_ID\"</li> <li>Copie o \"ID do diret\u00f3rio (locat\u00e1rio)\"</li> </ul> </li> <li>ARM_CLIENT_SECRET<ul> <li>Entre no registro criado na etapa \"ARM_CLIENT_ID\"</li> <li>Adicionar um certificado ou segredo &gt; + Novo segredo do cliente &gt; [Defina uma descri\u00e7\u00e3o/nome] &gt; Adicionar</li> <li>Copie \"Valor\"</li> </ul> </li> <li>ARM_SUBSCRIPTION_ID<ul> <li>Assinaturas &gt; [Selecione ou crie uma assinatura] &gt; IAM (Controle de acesso) &gt; Adicionar &gt; Adicionar atribui\u00e7\u00e3o de fun\u00e7\u00e3o &gt; Fun\u00e7\u00e3o &gt; Fun\u00e7\u00f5es de administrador priveligiadas<ul> <li>Contribuidor &gt; Pr\u00f3ximo</li> <li>Selecionar Membros &gt; [Nome do registro criado na etapa \"ARM_CLIENT_ID\"] &gt; Selecionar &gt; Pr\u00f3ximo </li> <li>Examinar + Atribuir</li> </ul> </li> <li>Assinaturas &gt; [Selecione a sua assinatura] &gt; Vis\u00e3o geral</li> <li>copie \"ID da Assinatura\"</li> </ul> </li> </ol>","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"dicas/terraform-pipeline/#terraform-pipeline-com-gitlab-ci","title":"Terraform pipeline com GitLab CI","text":"<p>Primeiro, fa\u00e7a o download deste projeto pr\u00e9-configurado do Terraform. O projeto est\u00e1 configurado para criar duas m\u00e1quinas virtuais (VMs), uma na AWS e outra na Azure. No entanto, os arquivos est\u00e3o ajustados para o meu ambiente, ent\u00e3o ser\u00e1 necess\u00e1rio realizar algumas modifica\u00e7\u00f5es para que funcionem corretamente no seu. Como o foco agora \u00e9 no pipeline, deixaremos as configura\u00e7\u00f5es detalhadas do Terraform para outro momento.</p> <p>Agora, o arquivo disponibilizado no zip chamado .gitlab-ci.yml \u00e9 respons\u00e1vel por automatizar o processo de execu\u00e7\u00e3o do Terraform. Nele, descrevemos as etapas que ser\u00e3o seguidas no pipeline de CI. Assim, sempre que realizarmos um push no reposit\u00f3rio do GitLab, o processo de integra\u00e7\u00e3o cont\u00ednua (CI) ser\u00e1 disparado automaticamente, executando o Terraform e provisionando o ambiente conforme as configura\u00e7\u00f5es definidas.</p> <p>gitlab-ci.yml Configura\u00e7\u00f5es de CI do GitLab<pre><code>stages:\n- validate_plan\n- apply\n- destroy\n\n.template:\n  image:\n    name: hashicorp/terraform:1.9\n    entrypoint: [\"\"]\n  before_script:\n  - terraform init\n\nvalidate &amp; plan:\n  extends: .template\n  stage: validate_plan\n  script:\n  - terraform validate\n  - terraform refresh\n  - terraform plan -out plan.out\n  cache:\n    key: plan\n    policy: push\n    paths:\n    - plan.out\n\napply:\n  extends: .template\n  stage: apply\n  script:\n  - terraform apply plan.out\n  cache:\n    key: plan\n    policy: pull\n    paths:\n    - plan.out\n  when: manual\n\ndestroy:\n  extends: .template\n  stage: destroy\n  script:\n  - terraform destroy -auto-approve\n  when: manual\n</code></pre></p> <p>Este arquivo est\u00e1 separado em tr\u00eas etapas, sendo:</p> <ul> <li>Validate &amp; plan: Para testar as configura\u00e7\u00f5es do terraform e criar um plano de implementa\u00e7\u00e3o</li> <li>apply: Aplica o plano de implementa\u00e7\u00e3o, ou seja, cria as VMs</li> <li>destroy: Destroi tudo que foi criado na etapa anterior. Est\u00e1 configurado para autoriza\u00e7\u00e3o manual, ou seja, precisa acessar o portal do GitLab e autorizar essa etapa.</li> </ul>","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"dicas/terraform-pipeline/#acompanhar-ci","title":"Acompanhar CI","text":"<p>Podemos acompanhar a execu\u00e7\u00e3o da pipeline pelo portal do GitLab em Compila\u00e7\u00e3o &gt; Pipelines, como identificado na imagem abaixo:</p> <p></p> <p>Na coluna \"Etapas\", est\u00e3o identificadas as tr\u00eas fases que configuramos no arquivo .gitlab-ci.yml: validate &amp; plan, apply e destroy. Embora seja bastante intuitivo, \u00e9 importante destacar o significado dos \u00edcones de status: o s\u00edmbolo vermelho indica uma falha que interrompe a execu\u00e7\u00e3o do pipeline; o amarelo representa um alerta que deve ser avaliado, mas n\u00e3o impede o avan\u00e7o do pipeline; o cinza indica que \u00e9 necess\u00e1ria uma intera\u00e7\u00e3o manual para prosseguir; e o verde confirma que tudo foi executado com sucesso.</p> <p>Ap\u00f3s a finaliza\u00e7\u00e3o da execu\u00e7\u00e3o da etapa de apply do pipeline, pode verificar em sua nuvem que os recursos configurados no terraform j\u00e1 foram criados com sucesso.</p>","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"dicas/terraform-pipeline/#finalizacao","title":"Finaliza\u00e7\u00e3o","text":"<p>Com isso conseguimos utilizar o Terraform num pipeline com o GitLab CI.</p> <p>Estou muito feliz por ter voc\u00ea aqui! Se precisar de algo, n\u00e3o hesite em me contactar. \ud83c\udf1f</p>","tags":["Terraform","Pipelines","GitLab","Azure","AWS"]},{"location":"home/aboutme/","title":"Um pouco sobre a minha trajet\u00f3ria profissional","text":"<p>Ol\u00e1! \ud83d\udc4b</p> <p>Bem-vindo \u00e0 minha Biblioteca de Documenta\u00e7\u00f5es!</p> <p>Aqui, vou compartilhar um pouco sobre mim e minha jornada nesse fascinante mundo da TI. \ud83d\ude80</p> <p>Minha trajet\u00f3ria come\u00e7ou cedo, aos 14 anos, quando iniciei como aprendiz na \u00e1rea de log\u00edstica. No entanto, minha paix\u00e3o por tecnologia sempre foi um grande motivador. Estudava por conta pr\u00f3pria e buscava entrar no mercado de TI o mais r\u00e1pido poss\u00edvel. Assim que meu contrato de aprendiz terminou, tive a oportunidade de trabalhar na Tigre, tamb\u00e9m como aprendiz, mas agora na \u00e1rea de TI. L\u00e1, auxiliei um analista s\u00eanior com a sustenta\u00e7\u00e3o do parque de computadores e foi nesse momento que tive a certeza de que a TI era minha verdadeira voca\u00e7\u00e3o. \ud83d\udcbb</p> <p>Determinando meu caminho, iniciei a faculdade de Redes de Computadores, o que abriu portas para novas oportunidades de emprego. Passei pela TI da Gidion, da TNGTEC e, atualmente, estou na Sercompe. Durante essas transi\u00e7\u00f5es, tive a chance de trabalhar com uma ampla gama de usu\u00e1rios, desde aqueles sem conhecimento t\u00e9cnico at\u00e9 engenheiros internacionais. Essa experi\u00eancia tamb\u00e9m ajudou a aprimorar meu ingl\u00eas. \ud83c\udf0d Embora ainda esteja em busca da flu\u00eancia total, estou sempre correndo atr\u00e1s dessa meta. </p> <p>Devido \u00e0s exig\u00eancias dos cargos que ocupei, n\u00e3o tive muitas oportunidades para me aprofundar no desenvolvimento de software. No entanto, recentemente, tive a chance de me dedicar mais ao desenvolvimento do que \u00e0 infraestrutura. Criei scripts de monitoramento que conectam APIs e bancos de dados e at\u00e9 desenvolvi uma ferramenta chamada ZmapL, que faz a correla\u00e7\u00e3o entre o monitoramento e a ferramenta de chamados. Clique aqui para saber mais sobre o ZmapL! </p> <p>Com essas novas necessidades, comecei a estudar programa\u00e7\u00e3o no final de 2022. Desde ent\u00e3o, tenho me aperfei\u00e7oado com uma P\u00f3s-Gradua\u00e7\u00e3o em Desenvolvimento Full Stack com Java e diversos cursos em plataformas como Alura, Udemy e Coursera, voltando-me para uma carreira mais DevOps. \ud83d\ude80\ud83d\udcbb</p> <p>Hoje, sou um profissional com s\u00f3lida experi\u00eancia em monitoramento e seguran\u00e7a de sistemas. Tenho um hist\u00f3rico comprovado em utilizar ferramentas como Zabbix e Grafana para garantir o desempenho e a integridade dos sistemas. Al\u00e9m disso, sou h\u00e1bil em desenvolver solu\u00e7\u00f5es eficientes com APIs, Python, ShellScript e PowerShell. \ud83d\udcc8</p> <p>Minha experi\u00eancia se estende ao gerenciamento e an\u00e1lise de dados com SQL e ao monitoramento de redes com SNMP. Tamb\u00e9m sou especializado em plataformas de seguran\u00e7a, como FortiGate e pfSense, garantindo que as infraestruturas estejam sempre protegidas contra amea\u00e7as. \ud83d\udd10</p> <p>Al\u00e9m disso, tenho um dom\u00ednio completo das solu\u00e7\u00f5es de virtualiza\u00e7\u00e3o VMware, incluindo NSX e Cloud Director, o que me permite criar e gerenciar ambientes virtuais robustos e escal\u00e1veis. \ud83d\udda5\ufe0f</p> <p>Fique \u00e0 vontade para explorar meus projetos e dicas. Espero que encontre informa\u00e7\u00f5es \u00fateis e inspiradoras! \ud83d\ude80\ud83d\udcda</p>"},{"location":"projetos/","title":"\ud83d\udee0\ufe0f Projetos","text":"<p>Bem-vindo \u00e0 minha se\u00e7\u00e3o pessoal de Projetos! Aqui, estou sempre buscando novas maneiras de enriquecer a experi\u00eancia e promover o amor pelo conhecimento.</p> <p>Nesta p\u00e1gina, voc\u00ea encontrar\u00e1 informa\u00e7\u00f5es detalhadas sobre as diversas iniciativas que estou desenvolvendo. Cada projeto \u00e9 concebido com muito cuidado e dedica\u00e7\u00e3o, sempre com o objetivo de trazer benef\u00edcios \u00e0 nossa comunidade.</p>","tags":["Introdu\u00e7\u00e3o"]},{"location":"projetos/deploy_vmware_cloud_director/","title":"Deploy VMware Cloud Director","text":"<p>Realizando o deploy de uma Cloud local utilizando VMware Cloud Director</p>","tags":["VMware vSphere","VMware NSX","VMware Cloud Director"]},{"location":"projetos/integrando_zabbix_com_otrs/","title":"Integrando Zabbix com o OTRS","text":"<p>Abertura de chamados automatizados com Zabbix e OTRS utilizando Python.</p> <p>EM DESENVOLVIMENTO...</p>","tags":["Zabbix","Python","API","SQL","OTRS"]},{"location":"projetos/zmapl/","title":"ZmapL","text":"<p>Mapeando eventos de um mesmo host no Zabbix para abrir ticket com diferentes caracteristicas.</p>","tags":["Zabbix","API","Angular","Node.js","OTRS"]},{"location":"projetos/zmapl/#motivacao","title":"Motiva\u00e7\u00e3o:","text":"<p>Durante nosso trabalho recente com o Zabbix, identificamos a necessidade de que um mesmo host abra tickets automaticamente, mas com caracter\u00edsticas distintas baseadas em seu nome. Essa necessidade surgiu devido ao nosso ambiente de Veeam, que gerencia jobs de v\u00e1rios clientes diferentes. Quando um chamado \u00e9 gerado automaticamente, gostar\u00edamos que ele fosse categorizado corretamente com o nome do cliente e o servi\u00e7o apropriado.</p>","tags":["Zabbix","API","Angular","Node.js","OTRS"]},{"location":"projetos/zmapl/#solucao","title":"Solu\u00e7\u00e3o:","text":"<p>Consideramos algumas abordagens, como segmentar os jobs em m\u00faltiplos hosts no Zabbix, com cada host dedicado a um cliente espec\u00edfico. No entanto, essa solu\u00e7\u00e3o complicaria a organiza\u00e7\u00e3o e a inclus\u00e3o de novos clientes. Assim, optamos por uma abordagem mais eficiente: utilizamos um arquivo JSON como um \"DE/PARA\" que mapeia o JOB com um prefixo e define as caracter\u00edsticas que o chamado deve ter. Baseando-se nesse arquivo, a automa\u00e7\u00e3o que desenvolvemos em Python cria tickets automaticamente no nosso sistema de chamados. A automa\u00e7\u00e3o identifica o evento de alerta de acordo com as caracter\u00edsticas atribu\u00eddas pelo JSON e, em seguida, gera um ticket atrav\u00e9s da API do sistema de chamados. No entanto, \u00e9 importante observar que manter e atualizar esse arquivo JSON, especialmente com v\u00e1rias pessoas envolvidas e quando clientes s\u00e3o adicionados, removidos ou modificados, pode ser suscet\u00edvel a erros.</p> <p>Para resolver esse problema, desenvolvemos uma aplica\u00e7\u00e3o web que facilita o gerenciamento desse arquivo. A solu\u00e7\u00e3o foi criada usando Angular para o frontend, Node.js para o backend e MySQL para o banco de dados. Toda a infraestrutura est\u00e1 containerizada com Docker e pode ser visualizada nos links abaixo:</p> <ul> <li>Projeto no GitHub</li> <li>Container Frontend</li> <li>Container Backend</li> </ul> <p></p>","tags":["Zabbix","API","Angular","Node.js","OTRS"]},{"location":"projetos/zmapl/#beneficios","title":"Benef\u00edcios:","text":"<p>Com essa solu\u00e7\u00e3o, qualquer usu\u00e1rio pode acessar o portal, chamado ZmapL (abrevia\u00e7\u00e3o de Zabbix Map to Ligero), para realizar as a\u00e7\u00f5es necess\u00e1rias. Isso traz mais facilidade, agilidade e reduz significativamente a incid\u00eancia de erros.</p>","tags":["Zabbix","API","Angular","Node.js","OTRS"]},{"location":"home/tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p>"},{"location":"home/tags/#api","title":"API","text":"<ul> <li>Integrando Zabbix com OTRS</li> <li>ZmapL</li> </ul>"},{"location":"home/tags/#aws","title":"AWS","text":"<ul> <li>Terraform pipeline</li> </ul>"},{"location":"home/tags/#angular","title":"Angular","text":"<ul> <li>ZmapL</li> </ul>"},{"location":"home/tags/#azure","title":"Azure","text":"<ul> <li>Terraform pipeline</li> </ul>"},{"location":"home/tags/#gitlab","title":"GitLab","text":"<ul> <li>Terraform pipeline</li> </ul>"},{"location":"home/tags/#html5","title":"HTML5","text":"<ul> <li>Markdown - Comandos B\u00e1sicos</li> </ul>"},{"location":"home/tags/#introducao","title":"Introdu\u00e7\u00e3o","text":"<ul> <li>\ud83d\udca1 Dicas</li> <li>\ud83d\udee0\ufe0f Projetos</li> </ul>"},{"location":"home/tags/#kubernetes","title":"Kubernetes","text":"<ul> <li>Kubernetes - Conceitos B\u00e1sicos</li> </ul>"},{"location":"home/tags/#linux","title":"Linux","text":"<ul> <li>Kubernetes - Conceitos B\u00e1sicos</li> </ul>"},{"location":"home/tags/#markdown","title":"Markdown","text":"<ul> <li>Markdown - Comandos B\u00e1sicos</li> </ul>"},{"location":"home/tags/#nodejs","title":"Node.js","text":"<ul> <li>ZmapL</li> </ul>"},{"location":"home/tags/#otrs","title":"OTRS","text":"<ul> <li>Integrando Zabbix com OTRS</li> <li>ZmapL</li> </ul>"},{"location":"home/tags/#pipelines","title":"Pipelines","text":"<ul> <li>Terraform pipeline</li> </ul>"},{"location":"home/tags/#python","title":"Python","text":"<ul> <li>Integrando Zabbix com OTRS</li> </ul>"},{"location":"home/tags/#sql","title":"SQL","text":"<ul> <li>Integrando Zabbix com OTRS</li> </ul>"},{"location":"home/tags/#terraform","title":"Terraform","text":"<ul> <li>Terraform pipeline</li> </ul>"},{"location":"home/tags/#vmware-cloud-director","title":"VMware Cloud Director","text":"<ul> <li>Deploy VMware Cloud Director</li> </ul>"},{"location":"home/tags/#vmware-nsx","title":"VMware NSX","text":"<ul> <li>Deploy VMware Cloud Director</li> </ul>"},{"location":"home/tags/#vmware-vsphere","title":"VMware vSphere","text":"<ul> <li>Deploy VMware Cloud Director</li> </ul>"},{"location":"home/tags/#zabbix","title":"Zabbix","text":"<ul> <li>Integrando Zabbix com OTRS</li> <li>ZmapL</li> </ul>"}]}